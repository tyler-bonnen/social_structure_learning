{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "% pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans as kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans as kmeans\n",
    "import numpy as np \n",
    "import os, csv, copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, csv, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(subject_id, day= 1, listen=0): \n",
    "    \"\"\"inputs: 'day' = int [1 OR 2]\n",
    "    returns a list of all subjects in gaze directory matching 'day'\"\"\"\n",
    "\n",
    "    data_file_names = []\n",
    "    data_path = '../../collection/gaze_data/'\n",
    "    folder_contents = os.listdir(data_path)\n",
    "    \n",
    "    for file in folder_contents: \n",
    "        if 'd%s.asc'%day in file and not 'x' in file: \n",
    "            data_file_names.append(file)\n",
    "\n",
    "    for file_name in data_file_names: \n",
    "        if str(subject_id) in file_name:    \n",
    "            if listen: print(file_name, subject_id)\n",
    "            subject_path = data_path + file_name\n",
    "\n",
    "    with open(subject_path) as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        subject_data = list(reader)\n",
    "\n",
    "    return subject_data\n",
    "\n",
    "def extract_data(subject_data): \n",
    "    \"\"\" \n",
    "    inputs: 'subject_data' = raw ascii file \n",
    "    returns: np.arrays for pupil, CS+, CS-, US, and movie_frame information \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    _pupil_ = [] \n",
    "    onsets  = []\n",
    "    cs_type = []\n",
    "    xy = []\n",
    "    xy_time = []\n",
    "    cs_pos = []; cs_p = 0 # CS+\n",
    "    cs_neg = []; cs_n = 0 # CS-\n",
    "    us_sti = []; us_o = 0 # US\n",
    "    fix_info = []\n",
    "    fix_duration = []\n",
    "    fix_xy = []\n",
    "    fix_time = [] \n",
    "    \n",
    "    # movie frame data prep \n",
    "    m_frame, i_frame = [], np.nan\n",
    "\n",
    "    for i_row in range(len(subject_data)): \n",
    "\n",
    "        msg = subject_data[i_row]  \n",
    "\n",
    "        try: \n",
    "            int(subject_data[i_row][0])\n",
    "            # 3 = pupil column\n",
    "            datum = float(msg[3]) \n",
    "            _pupil_.append(datum)\n",
    "            cs_pos.append(cs_p)\n",
    "            cs_neg.append(cs_n)\n",
    "            us_sti.append(us_o)\n",
    "            m_frame.append(i_frame)\n",
    "            \n",
    "            # extract xy coordinates \n",
    "            if ' .' in msg[1] or ' .' in  msg[2]:\n",
    "                xy.append([np.nan, np.nan])\n",
    "                xy_time.append(np.nan)\n",
    "            else: \n",
    "                xy.append([float(msg[1]), float(msg[2])])\n",
    "                xy_time.append(float(msg[0]))\n",
    "            \n",
    "        except: \n",
    "\n",
    "            if len(msg) > 1: \n",
    "                if 'CS+' in msg[1]: cs_p = 1\n",
    "                if 'CS-' in msg[1]: cs_n = 1\n",
    "                if 'US'  in msg[1]: \n",
    "                    us_o = 1\n",
    "                    cs_type[-1] =  cs_type[-1] + 'US'\n",
    "                    \n",
    "                    \n",
    "                if 'OFF' in msg[1]: \n",
    "                    cs_p = 0\n",
    "                    cs_n = 0\n",
    "                    us_o = 0 \n",
    "\n",
    "                if msg[0] == \"MSG\": \n",
    "\n",
    "                    if \"VFRAME\" in msg[1]: \n",
    "\n",
    "                        ind = str.find(msg[1], \"VFRAME\")\n",
    "                        space = str.find(msg[1], \" 0 0 /\")\n",
    "                        if space == -1: space = str.find(msg[1], \" 0 0 ../\")\n",
    "                        i_frame = int(msg[1][ind+7:space])\n",
    "                    \n",
    "                    if \"TRIAL_ONSET\" in msg[1]:\n",
    "                        onsets.append(len(_pupil_))\n",
    "                        cs_type.append(msg[1][-3:])\n",
    "                \n",
    "                if msg[0][0:4] == \"EFIX\":\n",
    "                    fix_info.append(msg)\n",
    "                    fix_duration.append(float(msg[2]))\n",
    "                    fix_xy.append((float(msg[3]),float(msg[4])))\n",
    "                    fix_time.append(float(msg[0][9:]))\n",
    "                    \n",
    "                        \n",
    "    fixation = {'xy':np.array(fix_xy), 'duration':np.array(fix_duration), 'info':fix_info, 'time':fix_time}\n",
    "    \n",
    "    stimuli = {\"CS+\":np.array(cs_pos), \"CS-\":np.array(cs_neg), \n",
    "               \"US\":np.array(us_sti), \"cs_type\":cs_type, \"onsets\":np.array(onsets)}\n",
    "    \n",
    "    data = {\"raw_pupil\":np.array(_pupil_), \n",
    "            \"movie_frame\":np.array(m_frame),\n",
    "            \"xy\":np.array(xy), \n",
    "            \"xy_time\":np.array(xy_time), \n",
    "            \"fixation\": fixation, \n",
    "            \"stimuli\": stimuli}\n",
    "                    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans_coordinates(xy, cut, n_clusters=3): \n",
    "   \n",
    "    if cut: \n",
    "        x_range, y_range = 1920, 1080\n",
    "        x_cut = np.array([0 < xy[ii,0] < x_range for ii in range(len(xy))])\n",
    "        y_cut = np.array([0 < xy[ii,1] < y_range for ii in range(len(xy))])\n",
    "        cuts = x_cut & y_cut\n",
    "        x = np.delete(xy[:,0], np.nonzero(cuts==False))\n",
    "        y = np.delete(xy[:,1], np.nonzero(cuts==False))\n",
    "        xy = np.stack((x,y)).T\n",
    "        \n",
    "\n",
    "    # ignore nans, flip (?) y axis, fit model\n",
    "    keep_inds = xy[:,0] == xy[:,0]\n",
    "    xy = xy[keep_inds]\n",
    "    \n",
    "    # correct for inversion depending on image type\n",
    "    k = kmeans(n_clusters=n_clusters, random_state=0).fit(xy)\n",
    "    \n",
    "    return k, xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_time_info(subject_data): \n",
    "    \n",
    "    CS_on = []\n",
    "    CS_off = [] \n",
    "    US = []\n",
    "    US_count = 0 \n",
    "    CS_count = 0\n",
    "    cs_type = [] \n",
    "    ref_count = 0\n",
    "    reinforcement = []\n",
    "    \n",
    "    \n",
    "    for ii in range(len(subject_data)): \n",
    "        msg = subject_data[ii] \n",
    "\n",
    "        if len(msg): \n",
    "            if msg[0] == \"MSG\" and \"VFRAME\" not in msg[1]: \n",
    "                \n",
    "                if 'ONSET' in msg[1] and 'TRIAL' in msg[1]: \n",
    "                    CS_on.append([CS_count, msg[1][:str.find(msg[1], ' ')], msg[1]])\n",
    "                    reinforcement.append(0)\n",
    "                    \n",
    "\n",
    "                if 'OFFSET' in msg[1] and 'TRIAL' in msg[1]: \n",
    "                    CS_off.append([CS_count, msg[1][:str.find(msg[1], ' ')], msg[1]])\n",
    "                    CS_count += 1 \n",
    "                \n",
    "                if 'US' in msg[1]: \n",
    "                    US.append([US_count, msg[1][:str.find(msg[1], ' ')], msg])\n",
    "                    US_count += 1 \n",
    "                    \n",
    "                    del reinforcement[-1]; reinforcement.append(1)\n",
    "    \n",
    "    return US, CS_on, CS_off, np.array(reinforcement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_gaze_stimuli(stim, sample_rate, time):\n",
    "    # find sample rate be second\n",
    "    gaze_behavior = []\n",
    "    figure(figsize=[15,5])\n",
    "    for i in range(len(stim)): \n",
    "        \n",
    "        # let's find the first US \n",
    "        us = int(stim[i][1])\n",
    "        # define the end of the interval to look over\n",
    "        n_seconds = 1\n",
    "        end_interval = us + sample_rate * n_seconds\n",
    "\n",
    "        # find indices for time we're interested in \n",
    "        i_behavior = (time < end_interval) & (time > us)\n",
    "        \n",
    "        subplot(2,3,i+1)\n",
    "        imshow(model_image,alpha=1)\n",
    "        scatter(data['xy'][:,0][i_behavior], data['xy'][:,1][i_behavior],c=range(len(np.nonzero(i_behavior)[0])), \n",
    "               #s=data['fixation']['duration'], \n",
    "                marker='o',\n",
    "                cmap=\"Blues\", alpha=.5)\n",
    "        ylim(1000,0)\n",
    "        axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject_names(day= 1, listen=0): \n",
    "\n",
    "    data_file_names = []\n",
    "    data_path = '../../collection/gaze_data/'\n",
    "    folder_contents = os.listdir(data_path)\n",
    "    \n",
    "    for file in folder_contents: \n",
    "        if 'd%s.asc'%day in file and not 'x' in file: \n",
    "            data_file_names.append(int(file[1:3]))\n",
    "\n",
    "    return data_file_names[18:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_clusters(data, show=1, cut=1, big_picture=0, fixation=1): # zzzz\n",
    "    \n",
    "    cluster_data = {}\n",
    "    \n",
    "    # colors, shape\n",
    "    colors = ['#00ccff', '#ff00ff', '#00ffaa']\n",
    "    y_len, x_len, _ = np.shape(model_image)\n",
    "    cluster_data['image_dims'] = {'x_len':x_len, 'y_len':y_len}\n",
    "    \n",
    "    if show: plt.figure(figsize=[15, 12])\n",
    "\n",
    "    # generate clusters\n",
    "    if fixation: \n",
    "        k, xy = kmeans_coordinates(data['fixation']['xy'], cut)\n",
    "    else: \n",
    "        k, xy = kmeans_coordinates(data['xy'], cut)\n",
    "\n",
    "    # save \n",
    "    cluster_data = {'data':data, 'k':k, 'xy':xy}\n",
    "\n",
    "    if show: \n",
    "\n",
    "        # find data to color mapping\n",
    "        point_colors = [colors[ii] for ii in k.labels_]\n",
    "        # setup plot\n",
    "        plt.subplot(1,2,i_subject+1); plt.axis('off')\n",
    "        # show background experimental stimuli\n",
    "        plt.imshow(model_image, alpha=.1)\n",
    "        # plot gaze data according to cluster color\n",
    "        plt.scatter(xy[:,0],xy[:,1],  alpha=.1, c = point_colors)\n",
    "        # extract centers of mass for each cluster\n",
    "        centers = np.round(k.cluster_centers_)\n",
    "\n",
    "        # plot center of mass for each cluster in a way we can clearly lable in legend\n",
    "        for i_loc in range(len(centers)):\n",
    "            plt.scatter(centers[i_loc][0], centers[i_loc][1], s=250, c='k')\n",
    "            plt.scatter(centers[i_loc][0], centers[i_loc][1], \n",
    "                        s=180, c=colors[i_loc], label='center of mass\\n  cluster_%s'%i_loc)\n",
    "            plt.annotate(i_loc, xy=(centers[i_loc][0], centers[i_loc][1]), \n",
    "                         xytext=(-4, -4), textcoords='offset points', alpha=1, fontsize=11)\n",
    "\n",
    "        # control aesthetics\n",
    "        if not big_picture: \n",
    "            plt.xlim([0, x_len]), \n",
    "            plt.ylim([y_len, 0])\n",
    "        plt.legend(); ax = plt.gca(); ax.legend(fontsize = 6+1, loc=3)\n",
    "        plt.title(\"\\nexperimental average from centers of mass: %.02f pixels\\n\" \n",
    "                  %(np.sqrt(k.inertia_/len(xy)) ) )\n",
    "\n",
    "    return cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get rid of the need for model data. FRom a number to this kind of character string\n",
    "# make scripts able to take in fixation data only\n",
    "model_image_ = Image.open('model_image.png')\n",
    "x_range, y_range = 1920, 1080\n",
    "model_image = model_image_.resize((x_range, y_range), Image.ANTIALIAS)\n",
    "include_radius = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_subject_data(i_subject): \n",
    "    \n",
    "\n",
    "    reference_points = {'face' :[300,  300], \n",
    "                        'wrist':[900,  900], \n",
    "                        'stim' :[1550, 400]}\n",
    "\n",
    "    subject_data = load_data(i_subject)\n",
    "    data = extract_data(subject_data)\n",
    "    structured_data = generate_clusters(data, show=0)\n",
    "    duration = data['fixation']['duration']\n",
    "    centers = structured_data['k'].cluster_centers_\n",
    "    xy = structured_data['xy'] \n",
    "\n",
    "    plt.figure(figsize=[20,8]); i_plot = 1\n",
    "    _roi_ = {} \n",
    "    for i_reference in reference_points.keys(): \n",
    "\n",
    "        # calculate\n",
    "        i_center = np.sum(abs(centers - reference_points[i_reference]),1).argmin()\n",
    "        center_of_mass = centers[i_center,:] - (centers[i_center,:] - reference_points[i_reference])/2\n",
    "        distance_from = np.sum(abs(xy - center_of_mass),1)\n",
    "        include = distance_from < include_radius\n",
    "        percent_ROI = round(sum(duration[include])/ sum(duration) * 100)\n",
    "        n_ROI = round(len(duration[include])/ float(len(duration)) * 100)\n",
    "\n",
    "        # save \n",
    "        _roi_[i_reference] = percent_ROI\n",
    "\n",
    "        # show\n",
    "        plt.subplot(1,3,i_plot); i_plot += 1 \n",
    "        plt.imshow(model_image, alpha=.3) ; plt.axis('off')\n",
    "        plt.scatter(xy[:,0], xy[:,1], c=include, s=data['fixation']['duration'], alpha=.05, cmap='cool', label='fixations')    \n",
    "        plt.scatter(centers[i_center,0], centers[i_center,1], color='purple', s=50, alpha=.9, label='cluster COM')\n",
    "        plt.scatter(reference_points[i_reference][0], reference_points[i_reference][1], color='red', s=50, alpha=.9, label='image reference')\n",
    "        plt.scatter(center_of_mass[0], center_of_mass[1], color='red', s=50, alpha=.5, label='halfway')\n",
    "        #plt.legend(fontsize=8)\n",
    "        plt.title('s%s %s ROI \\n %s percent of the time %s percent of fixations'%(i_subject, i_reference, percent_ROI, n_ROI))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def temporal_gaze_analysis(subject_data, reference_points, include_radius, interval_length):      \n",
    "        \n",
    "    gaze_analysis = {} \n",
    "    \n",
    "    # extract relevent information\n",
    "    data = extract_data(subject_data)  \n",
    "\n",
    "    # identify CS and US timing withing gaze data # tyler: combine functions later\n",
    "    US_onsets, CS_onsets, CS_offsets, reinforcement = extract_time_info(subject_data)\n",
    "    \n",
    "    # generate clusters \n",
    "    structured_data = generate_clusters(data, show=0)\n",
    "    \n",
    "    # extract centers of each cluster\n",
    "    centers = structured_data['k'].cluster_centers_\n",
    "    \n",
    "    # high level analysis types\n",
    "    analysis_types = [   'CS'    , \n",
    "                      'US_onset' , \n",
    "                      'CS_offset', \n",
    "                      'interval']\n",
    "    \n",
    "    for analysis in analysis_types: \n",
    "        \n",
    "        gaze_analysis[analysis] = {}\n",
    "        \n",
    "        # determine sample rate with known interval (CS length = 4 seconds)\n",
    "        sample_rate = (int(CS_offsets[0][1]) - int(CS_onsets[0][1])) / 4\n",
    "\n",
    "        # specific options for CS or US \n",
    "        if analysis ==    'CS'    :  n_stimuli = len(CS_onsets)\n",
    "        if analysis == 'US_onset' :  n_stimuli = len(US_onsets)        \n",
    "        if analysis == 'CS_offset':  n_stimuli = len(CS_offsets)\n",
    "        if analysis == 'interval' :  n_stimuli = len(CS_onsets)-2\n",
    "            \n",
    "        # time and location infor for all eye data\n",
    "        gaze_time = np.array(data['xy_time']) \n",
    "        gaze_xy = np.array(data['xy']) \n",
    "\n",
    "        gaze_data = {'face' :np.zeros(n_stimuli), \n",
    "                     'wrist':np.zeros(n_stimuli), \n",
    "                     'stim' :np.zeros(n_stimuli),\n",
    "                     'sum'  :np.zeros(n_stimuli)}\n",
    "               \n",
    "        for i_stim in range(n_stimuli): \n",
    "\n",
    "            # define type_dependent interval to look over\n",
    "            if analysis == 'CS': \n",
    "\n",
    "                stimulus_onset  = int(CS_onsets[i_stim][1])\n",
    "                stimulus_offset = int(CS_offsets[i_stim][1])                \n",
    "                #cs_type.append(CS_onsets[i_stim][2][-3:])\n",
    "            \n",
    "            if analysis == 'interval':\n",
    "                \n",
    "                stimulus_onset  = int(CS_offsets[i_stim+1][1]) \n",
    "                stimulus_offset = int(CS_onsets[i_stim+2][1]) \n",
    "                \n",
    "            if analysis == 'US_onset': \n",
    "                \n",
    "                # US is 1 second after US onset signal sent to eyelink\n",
    "                stimulus_onset  = int(US_onsets[i_stim][1]) + sample_rate * 1\n",
    "                stimulus_offset = stimulus_onset + sample_rate * interval_length\n",
    "            \n",
    "            if analysis == 'CS_offset':\n",
    "                \n",
    "                stimulus_onset  = int(CS_offsets[i_stim][1]) \n",
    "                stimulus_offset = stimulus_onset + sample_rate * interval_length\n",
    "\n",
    "            # find indices for time we're interested in\n",
    "            gaze_analysis_window = (gaze_time < stimulus_offset) & (gaze_time > stimulus_onset)\n",
    "            \n",
    "            # extract indices from fixation and gaze timecourses\n",
    "            i_gaze_xy = gaze_xy[gaze_analysis_window]\n",
    "            \n",
    "            # if there's no gaze data during this window, go to next time window\n",
    "            if len(i_gaze_xy) < 1: gaze_data[i_reference][i_stim] = np.nan ; continue \n",
    "            \n",
    "            # iterate through AOIs (face, wrist, stim)\n",
    "            for i_reference in reference_points.keys(): \n",
    "\n",
    "                # find which cluster-based center is closest to the image-based center\n",
    "                i_center = np.sum(abs(centers - reference_points[i_reference]),1).argmin()\n",
    "                \n",
    "                # find halfway point between image and cluster based center of mass \n",
    "                center_of_mass = centers[i_center,:] - (centers[i_center,:] - reference_points[i_reference])/2\n",
    "            \n",
    "                # calculate distance between each measure and AOI\n",
    "                distance_from_gaze = np.sum(abs(i_gaze_xy - center_of_mass),1)\n",
    "                \n",
    "                # determine which indices are within the AOI\n",
    "                include_gaze = distance_from_gaze  < include_radius\n",
    "    \n",
    "                # calculate percentage of measures that fall within the AOI \n",
    "                percent_gaze_AOI = sum(include_gaze) / float(sum(gaze_analysis_window))\n",
    "\n",
    "                # remove nans\n",
    "                if percent_gaze_AOI != percent_gaze_AOI : percent_gaze_AOI = 0.0\n",
    "                \n",
    "                # save \n",
    "                gaze_data[i_reference][i_stim] = round(percent_gaze_AOI * 100,1)\n",
    "        \n",
    "        # transfer\n",
    "        gaze_analysis[analysis] = gaze_data\n",
    "        \n",
    "    return gaze_analysis # return\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run analyses for multiple distributions of attention over 3 areas of interest\n",
    "\n",
    "def return_gaze_analysis_data(): \n",
    "    \n",
    "    gaze_data = {}\n",
    "\n",
    "    # pixel size of AOI\n",
    "    include_radius = 200\n",
    "\n",
    "    # len(intervals) in seconds \n",
    "    interval_length = 1 \n",
    "\n",
    "    # subject's to run analysis on\n",
    "    subjects = get_subject_names()[0:2]\n",
    "\n",
    "    # define ROI centers on reference image \n",
    "    reference_points = {'face' :[300,  300], \n",
    "                        'wrist':[900,  900], \n",
    "                        'stim' :[1550, 400]}\n",
    "\n",
    "    for i_subject in subjects: \n",
    "\n",
    "        # load edf (asc) file\n",
    "        subject_data = load_data(i_subject)\n",
    "\n",
    "        # run analysis to determine percent of time for each ROI \n",
    "        gaze_data[i_subject] = temporal_gaze_analysis(subject_data, reference_points, include_radius, interval_length)\n",
    "\n",
    "    # reorder data into subject averages\n",
    "    main = {}\n",
    "    for analysis_type in gaze_data[i_subject].keys(): \n",
    "        main[analysis_type] = {}\n",
    "        for key in reference_points.keys(): \n",
    "            main[analysis_type][key] = [np.mean(gaze_data[sub][analysis_type][key]) for sub in subjects]\n",
    "    \n",
    "    return main, gaze_data, subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main, gaze_data, subjects = return_gaze_analysis_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = subjects[0]\n",
    "labels = main['CS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print 'interval:', zip(labels, [round(mean(gaze_data[sub]['interval'][_type_])) for _type_ in labels])\n",
    "# print 'CS_offset:', zip(labels,[round(mean(gaze_data[sub]['CS_offset'][_type_])) for _type_ in labels])\n",
    "# print 'CS:', zip(labels,[round(mean(gaze_data[sub]['CS'][_type_])) for _type_ in labels]) \n",
    "# print 'US_onset:', zip(labels,[round(mean(gaze_data[sub]['US_onset'][_type_])) for _type_ in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_subject_data(sub) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gaze_functions as attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_function, gaze_data_function, subjects_function = attention.return_gaze_analysis_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = main['CS'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types = gaze_data[sub].keys()\n",
    "keys = main['CS'].keys()\n",
    "figure(figsize=[13,8])\n",
    "\n",
    "for i_type in range(len(types)): \n",
    "    subplot(2,2,i_type+1)\n",
    "    place = np.ones(len(gaze_data[sub][types[i_type]][keys[0]]))\n",
    "    jitter = np.random.randn(len(place))/30\n",
    "    [scatter(place-ii + jitter, gaze_data[sub][types[i_type]][keys[ii]], alpha=.2) for ii in range(len(keys))];\n",
    "    xticks([1, 0, -1], [keys[0], keys[1], keys[2]])\n",
    "    ylim(-5,110)\n",
    "    title('subject %s during %s'%(sub, types[i_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'face v wrist' , ' p < %.4f' %stats.ttest_ind(gaze_data[sub]['US_onset']['face'], gaze_data[sub]['US_onset']['wrist'])[1]\n",
    "print 'face v stim'  , ' p < %.4f' %stats.ttest_ind(gaze_data[sub]['US_onset']['face'], gaze_data[sub]['US_onset']['stim'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=[13,9])\n",
    "\n",
    "count = 1\n",
    "for i_type in types:\n",
    "    place = np.ones(len(main[i_type][keys[0]]))\n",
    "    subplot(2,2,count); count += 1     \n",
    "    for i_key, j_key in zip(keys, range(len(keys))): \n",
    "        jitter = np.random.randn(len(place))/30\n",
    "        scatter(place-j_key+jitter, main[i_type][i_key], alpha=.2) \n",
    "    xlim(-1.5,1.5)\n",
    "    xticks([1, 0, -1], [keys[0], keys[1], keys[2]])\n",
    "    ylim(-10,110)\n",
    "    yticks([0,50,100])\n",
    "    ylabel('percent of looking time')\n",
    "    \n",
    "    title(i_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare = 'face'\n",
    "print compare , ' p < %.4f' %stats.ttest_ind(main['US_onset']['stim'], main['CS'][compare])[1]\n",
    "compare = 'stim'\n",
    "print compare , ' p < %.4f' %stats.ttest_ind(main['US_onset']['stim'], main['CS'][compare])[1]\n",
    "compare = 'wrist'\n",
    "print compare , 'p < %.4f' %stats.ttest_ind(main['US_onset']['stim'], main['CS'][compare])[1]\n",
    "\n",
    "print '\\nsignificance of wrist after shock (p < %s)'%round(stats.ttest_1samp(main['US_onset']['wrist'], 0)[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def roi_percent_analysis(subjects, show=0): \n",
    "        \n",
    "    roi_data = {} \n",
    "    \n",
    "    for i_subject in range(len(subjects)):\n",
    "        \n",
    "        subject_data = load_data(subjects[i_subject])\n",
    "        data = extract_data(subject_data)\n",
    "        structured_data = generate_clusters(data, show=0)\n",
    "        centers = structured_data['k'].cluster_centers_\n",
    "        duration = structured_data['data']['fixation']['duration']\n",
    "        xy = structured_data['xy'] \n",
    "\n",
    "        _roi_ = {} \n",
    "\n",
    "        if show: plt.figure(figsize=[20,8]); i_plot = 1\n",
    "\n",
    "        for i_reference in reference_points.keys(): \n",
    "\n",
    "            # calculate\n",
    "            i_center = np.sum(abs(centers - reference_points[i_reference]),1).argmin()\n",
    "            center_of_mass = centers[i_center,:] - (centers[i_center,:] - reference_points[i_reference])/2\n",
    "            distance_from = np.sum(abs(xy - center_of_mass),1)\n",
    "            include = distance_from < include_radius\n",
    "            percent_ROI = round(sum(duration[include])/ sum(duration) * 100)\n",
    "            n_ROI = round(len(duration[include])/ float(len(duration)) * 100)\n",
    "\n",
    "            # save \n",
    "            _roi_[i_reference] = percent_ROI\n",
    "\n",
    "            if show: \n",
    "                plt.subplot(1,3,i_plot); i_plot += 1 \n",
    "                plt.imshow(model_image, alpha=.3) ; plt.axis('off')\n",
    "                plt.scatter(xy[:,0], xy[:,1], c=include, s=data['fixation']['duration'], alpha=.05, cmap='cool', label='fixations')    \n",
    "                plt.scatter(centers[i_center,0], centers[i_center,1], color='purple', s=50, alpha=.9, label='cluster COM')\n",
    "                plt.scatter(reference_points[i_reference][0], reference_points[i_reference][1], color='red', s=50, alpha=.9, label='image reference')\n",
    "                plt.scatter(center_of_mass[0], center_of_mass[1], color='red', s=50, alpha=.5, label='halfway')\n",
    "                #plt.legend(fontsize=8)\n",
    "                plt.title('s%s %s ROI \\n %s percent of the time %s percent of fixations'%(subjects[i_subject], i_reference, percent_ROI, n_ROI))\n",
    "\n",
    "        roi_data[i_subject] = _roi_ \n",
    "    \n",
    "    return roi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def temporal_gaze_analysis(subject_data, reference_points, include_radius, interval_length):\n",
    "            \n",
    "#     # extract relevent information\n",
    "#     data = extract_data(subject_data)  \n",
    "\n",
    "#     # identify CS and US timing withing gaze data # tyler: combine functions later\n",
    "#     US_onsets, CS_onsets, CS_offsets, reinforcement = extract_time_info(subject_data)\n",
    "    \n",
    "#     # generate clusters \n",
    "#     structured_data = generate_clusters(data, show=0)\n",
    "    \n",
    "#     # extract centers of each cluster\n",
    "#     centers = structured_data['k'].cluster_centers_\n",
    "    \n",
    "#     # high level analysis types\n",
    "#     analysis_types = ['CS_onset', \n",
    "#                       'US_onset', \n",
    "#                       'CS_offset']\n",
    "    \n",
    "#     # global data structure\n",
    "#     gaze_analysis = {}\n",
    "    \n",
    "#     for analysis in analysis_types: \n",
    "        \n",
    "#         gaze_analysis\n",
    "#         # determine sample rate with known interval (CS length = 4 seconds)\n",
    "#         sample_rate = (int(CS_offsets[0][1]) - int(CS_onsets[0][1])) / 4\n",
    "\n",
    "#         # specific options for CS or US \n",
    "#         if   analysis == 'CS_onset' :  n_stimuli = len(CS_on)\n",
    "#         elif analysis == 'US_onset' :  n_stimuli = len(US)        \n",
    "#         elif analysis == 'CS_offset':  n_stimuli = len(CS_off)\n",
    "            \n",
    "#         # time and location info of fixation\n",
    "#         fix_time = np.array(data['fixation']['time']) \n",
    "#         fix_xy = np.array(data['fixation']['xy']) \n",
    "#         fix_duration = np.array(data['fixation']['duration'])\n",
    "        \n",
    "#         # time and location infor for all eye data\n",
    "#         gaze_time = np.array(data['xy_time']) \n",
    "#         gaze_xy = np.array(data['xy']) \n",
    "        \n",
    "#         for i_stim in range(n_stimuli): \n",
    "\n",
    "#             # define type_dependent interval to look over\n",
    "#             if analysis == 'CS_onset': \n",
    "\n",
    "#                 stimulus_onset  = int(CS_onsets[i_stim][1])\n",
    "#                 stimulus_offset = int(CS_offsets[i_stim][1])                \n",
    "#                 roi_data['type'].append(CS_onsets[i_stim][2][-3:])\n",
    "            \n",
    "#             if analysis == 'US_onset': \n",
    "                \n",
    "#                 # US is 1 second after US onset signal sent to eyelink\n",
    "#                 stimulus_onset  = int(US_onsets[i_stim][1]) + sample_rate * 1\n",
    "#                 stimulus_offset = stimulus_onset + sample_rate * interval_length\n",
    "\n",
    "#             if analysis == 'CS_offset':\n",
    "                \n",
    "#                 stimulus_onset  = int(CS_offsets[i_stim][1]) \n",
    "#                 stimulus_offset = stimulus_onset + sample_rate * interval_length\n",
    "\n",
    "#             # find indices for time we're interested in\n",
    "#             gaze_analysis_window = (gaze_time < stimulus_offset) & (gaze_time > stimulus_onset)\n",
    "#             fix_analysis_window = (fix_time  < stimulus_offset) & (fix_time  > stimulus_onset)\n",
    "            \n",
    "#             # extract indices from fixation and gaze timecourses\n",
    "#             i_gaze_xy = gaze_xy[gaze_analysis_window]\n",
    "#             i_fix_xy  = fix_xy[fix_analysis_window]\n",
    "#             i_fix_dur = duration[fix_analysis_window]\n",
    "\n",
    "#             stim_sum_f, stim_sum_g = [], []\n",
    "            \n",
    "#             # iterate through AOIs (face, wrist, stim)\n",
    "#             for i_reference in reference_points.keys(): \n",
    "\n",
    "#                 # find which cluster-based center is closest to the image-based center\n",
    "#                 i_center = np.sum(abs(centers - reference_points[i_reference]),1).argmin()\n",
    "                \n",
    "#                 # find halfway point between image and cluster based center of mass \n",
    "#                 center_of_mass = centers[i_center,:] - (centers[i_center,:] - reference_points[i_reference])/2\n",
    "            \n",
    "#                 # calculate distance between each measure and AOI\n",
    "#                 distance_from_gaze      = np.sum(abs(i_gaze_xy - center_of_mass),1)\n",
    "#                 distance_from_fixation  = np.sum(abs(i_fix_xy  - center_of_mass),1)\n",
    "                \n",
    "               \n",
    "#                 # determine which indices are within the AOI\n",
    "#                 include_gaze     = distance_from_gaze     < include_radius\n",
    "#                 include_fixation = distance_from_fixation < include_radius\n",
    "\n",
    "#                 # calculate percentage of measures that fall within the AOI \n",
    "#                 percent_fixation_ROI = sum(i_fix_dur[include_fixation]) / sum(i_fix_dur)\n",
    "#                 percent_gaze_ROI     = (100* sum(include_gaze) / float(len(i_gaze_xy))) \n",
    "\n",
    "                \n",
    "#                 # remove nans\n",
    "#                 if percent_fixation_ROI != percent_fixation_ROI: percent_fixation_ROI = 0.0\n",
    "#                 if percent_gaze_ROI     != percent_gaze_ROI    : percent_gaze_ROI     = 0.0\n",
    "\n",
    "#                 roi_data[i_reference]['gaze'].append(percent_gaze_ROI)\n",
    "#                 roi_data[i_reference]['fixation'].append(percent_fixation_ROI)\n",
    "                \n",
    "#                 stim_sum_g.append(percent_gaze_ROI)\n",
    "#                 stim_sum_f.append(percent_fixation_ROI)\n",
    "            \n",
    "#             roi_data[i_reference]['sum_gaze'].append(sum(stim_sum_g))\n",
    "#             roi_data[i_reference]['sum_fixation'].append(sum(stim_sum_f))\n",
    "\n",
    "#         gaze_analysis[analysis] = roi_data\n",
    "        \n",
    "#     return gaze_analysis, roi_data\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
